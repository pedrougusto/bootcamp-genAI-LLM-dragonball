# ğŸ‰ Dragon Ball GenAI â€” LLM with Custom Knowledge Base

> **Bootcamp project:** Building a domain-specific LLM assistant grounded on Dragon Ball universe lore using Retrieval-Augmented Generation (RAG).

---

## Overview

This project was developed as part of a **Generative AI Bootcamp** and explores how to build a conversational AI assistant that answers questions about the Dragon Ball universe with accuracy and context.

Instead of relying solely on a general-purpose LLM's training data, the pipeline ingests structured knowledge sources about Dragon Ball's story, characters, sagas, and lore â€” grounding the model's responses in a curated knowledge base.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   KNOWLEDGE SOURCES                  â”‚
â”‚   Dragon Ball lore Â· Character bios Â· Saga summaries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     Document Ingestion   â”‚
              â”‚   Chunking + Embedding   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚       Vector Store       â”‚
              â”‚  Semantic similarity     â”‚
              â”‚        retrieval         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        LLM Layer         â”‚
              â”‚  Context-aware response  â”‚
              â”‚       generation         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     Conversational UI    â”‚
              â”‚   Q&A about Dragon Ball  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What it does

The assistant answers questions grounded in Dragon Ball lore, such as:

- *"What are the transformations of Goku and what triggers each one?"*
- *"Summarize the Frieza Saga and its key battles."*
- *"Who is the strongest character in Dragon Ball Super and why?"*
- *"What is the difference between Dragon Ball Z and Dragon Ball GT?"*

Responses are generated by retrieving the most relevant passages from the knowledge base and passing them as context to the language model â€” a classic **RAG (Retrieval-Augmented Generation)** pattern.

---

## Tech Stack

| Component | Technology |
|---|---|
| **LLM** | Gemini / OpenAI GPT |
| **Embeddings** | Google Generative AI Embeddings |
| **Vector Store** | FAISS / Chroma |
| **Orchestration** | LangChain / NotebookLM |
| **Notebook** | Google Colab |
| **Knowledge Base** | Custom Dragon Ball lore documents |

---

## Key Concepts Demonstrated

**RAG (Retrieval-Augmented Generation)**
Rather than fine-tuning the model, relevant knowledge is retrieved at query time and injected into the prompt. This allows the LLM to answer accurately about a niche domain without retraining.

**Document Chunking**
Source documents are split into semantically coherent chunks before embedding, balancing retrieval precision with context richness.

**Semantic Search**
User questions are embedded and matched against the knowledge base using cosine similarity, ensuring the most relevant passages are retrieved even when the wording differs from the source.

**Prompt Engineering**
The system prompt instructs the model to answer only based on retrieved context, reducing hallucination and keeping responses grounded in Dragon Ball canon.

---

## Project Structure

```
bootcamp-genAI-LLM-DragonBall/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ dragonball_rag_pipeline.ipynb   # Main notebook
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dragonball_lore/                # Knowledge base documents
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py                    # Document loading & chunking
â”‚   â”œâ”€â”€ embeddings.py                   # Embedding generation
â”‚   â””â”€â”€ retrieval.py                    # Semantic search & RAG chain
â””â”€â”€ README.md
```

---

## Example Interaction

```
User:  Who is stronger, Goku or Vegeta?

Model: Based on the Dragon Ball lore, both warriors have achieved
       comparable power levels across different sagas. In Dragon Ball Super,
       both reached Ultra Instinct and Super Saiyan Blue Evolved respectively.
       However, Goku has more consistently pushed beyond his limits in
       critical battles, suggesting a slight edge â€” though Vegeta's
       rivalry drives continuous evolution in both fighters.
       [Source: Dragon Ball Super â€” Tournament of Power arc]
```

---

## What I learned

- How to structure a **RAG pipeline** end-to-end: ingestion â†’ chunking â†’ embedding â†’ retrieval â†’ generation
- The importance of **chunk size tuning** â€” too small loses context, too large dilutes relevance
- How **prompt engineering** controls hallucination in domain-specific assistants
- Practical use of **vector similarity search** for semantic retrieval

---

## About this project

Developed during the **Generative AI Bootcamp**, this project demonstrates how GenAI techniques can be applied to any knowledge domain â€” the Dragon Ball theme makes the concepts approachable and fun to demonstrate, while the underlying architecture is directly transferable to real-world use cases like internal knowledge bases, customer support bots, and document Q&A systems.

---

*Part of [Pedro Augusto's Data & AI Portfolio](https://github.com/YOUR_USERNAME)*

---
---

# ğŸ‰ Dragon Ball GenAI â€” LLM com Base de Conhecimento Customizada

> **Projeto de Bootcamp:** ConstruÃ§Ã£o de um assistente LLM especializado no universo Dragon Ball usando Retrieval-Augmented Generation (RAG).

---

## VisÃ£o Geral

Este projeto foi desenvolvido durante um **Bootcamp de InteligÃªncia Artificial Generativa** e explora como construir um assistente conversacional capaz de responder perguntas sobre o universo Dragon Ball com precisÃ£o e contexto.

Em vez de depender apenas do conhecimento de treinamento de um LLM genÃ©rico, o pipeline ingere fontes estruturadas sobre a histÃ³ria, personagens, sagas e lore do Dragon Ball â€” ancorando as respostas do modelo em uma base de conhecimento curada.

---

## Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FONTES DE CONHECIMENTO              â”‚
â”‚   Lore Dragon Ball Â· Fichas de personagens Â· Sagas   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    IngestÃ£o de Docs      â”‚
              â”‚  Chunking + Embeddings   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      Vector Store        â”‚
              â”‚  Busca por similaridade  â”‚
              â”‚        semÃ¢ntica         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚       Camada LLM         â”‚
              â”‚  GeraÃ§Ã£o de resposta     â”‚
              â”‚   com contexto           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚       Interface Q&A      â”‚
              â”‚  Perguntas sobre DBZ     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## O que o projeto faz

O assistente responde perguntas ancoradas no lore do Dragon Ball, como:

- *"Quais sÃ£o as transformaÃ§Ãµes do Goku e o que desencadeia cada uma?"*
- *"Resuma a Saga de Freeza e suas batalhas principais."*
- *"Qual Ã© o personagem mais forte no Dragon Ball Super e por quÃª?"*
- *"Qual a diferenÃ§a entre Dragon Ball Z e Dragon Ball GT?"*

As respostas sÃ£o geradas recuperando as passagens mais relevantes da base de conhecimento e passando-as como contexto ao modelo de linguagem â€” o padrÃ£o clÃ¡ssico de **RAG (Retrieval-Augmented Generation)**.

---

## Stack

| Componente | Tecnologia |
|---|---|
| **LLM** | Gemini / OpenAI GPT |
| **Embeddings** | Google Generative AI Embeddings |
| **Vector Store** | FAISS / Chroma |
| **OrquestraÃ§Ã£o** | LangChain / NotebookLM |
| **Notebook** | Google Colab |
| **Base de Conhecimento** | Documentos customizados sobre Dragon Ball |

---

## Conceitos Demonstrados

**RAG (Retrieval-Augmented Generation)**
Em vez de fazer fine-tuning no modelo, o conhecimento relevante Ã© recuperado em tempo de consulta e injetado no prompt. Isso permite ao LLM responder com precisÃ£o sobre um domÃ­nio especÃ­fico sem retreinamento.

**Chunking de Documentos**
Os documentos fonte sÃ£o divididos em partes semanticamente coerentes antes do embedding, equilibrando precisÃ£o na recuperaÃ§Ã£o com riqueza de contexto.

**Busca SemÃ¢ntica**
As perguntas do usuÃ¡rio sÃ£o transformadas em embeddings e comparadas com a base de conhecimento por similaridade de cosseno â€” garantindo que as passagens mais relevantes sejam recuperadas mesmo quando a formulaÃ§Ã£o difere da fonte.

**Engenharia de Prompt**
O system prompt instrui o modelo a responder apenas com base no contexto recuperado, reduzindo alucinaÃ§Ãµes e mantendo as respostas fiÃ©is ao cÃ¢none Dragon Ball.

---

## Estrutura do Projeto

```
bootcamp-genAI-LLM-DragonBall/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ dragonball_rag_pipeline.ipynb   # Notebook principal
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dragonball_lore/                # Documentos da base de conhecimento
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py                    # Carregamento e chunking de documentos
â”‚   â”œâ”€â”€ embeddings.py                   # GeraÃ§Ã£o de embeddings
â”‚   â””â”€â”€ retrieval.py                    # Busca semÃ¢ntica e cadeia RAG
â””â”€â”€ README.md
```

---

## O que aprendi

- Como estruturar um **pipeline RAG** de ponta a ponta: ingestÃ£o â†’ chunking â†’ embedding â†’ recuperaÃ§Ã£o â†’ geraÃ§Ã£o
- A importÃ¢ncia do **ajuste do tamanho do chunk** â€” muito pequeno perde contexto, muito grande dilui a relevÃ¢ncia
- Como **engenharia de prompt** controla alucinaÃ§Ãµes em assistentes de domÃ­nio especÃ­fico
- Uso prÃ¡tico de **busca vetorial por similaridade semÃ¢ntica**

---

## Sobre este projeto

Desenvolvido durante o **Bootcamp de InteligÃªncia Artificial Generativa**, este projeto demonstra como tÃ©cnicas de GenAI podem ser aplicadas a qualquer domÃ­nio de conhecimento. O tema Dragon Ball torna os conceitos acessÃ­veis e divertidos de demonstrar, mas a arquitetura subjacente Ã© diretamente transferÃ­vel para casos de uso reais como bases de conhecimento internas, bots de suporte ao cliente e sistemas de Q&A sobre documentos.

---

*Parte do [PortfÃ³lio de Dados & IA do Pedro Augusto](https://github.com/YOUR_USERNAME)*
